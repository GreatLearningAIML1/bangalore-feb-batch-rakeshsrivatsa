{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment_Rakesh.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfMmMnPJjvn",
        "colab_type": "text"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjcGOJhcJjvp",
        "colab_type": "text"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0Pl2XjJjvq",
        "colab_type": "text"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlDDmjpE3JcV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbb5aba8-e6f1-4bb9-c445-8d9d14b0388b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr75v_UYJjvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "78ef6742-a3a2-4dcb-c323-3e5b7de4bc8c"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 9us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 4s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 2s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTI42-0qJjvw",
        "colab_type": "text"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zewyDcBlJjv1",
        "colab_type": "code",
        "outputId": "94037d5e-ef6f-4658-c834-1b7b3c002a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxsWKa-13_aV",
        "colab_type": "code",
        "outputId": "7b635579-cd2a-4913-eb14-30b1883e8029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WytT2eRnJjv4",
        "colab_type": "text"
      },
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIsXy1EEcNHQ",
        "colab_type": "code",
        "outputId": "a670cd9c-e4ff-468f-8df7-8c5d4c6eb0cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Dimensions for test data are : {0} x {1}\".format(x_test.shape[1],x_test.shape[2]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensions for test data are : 28 x 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_snl9jkBBZu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78180bda-814c-41f6-95e5-a8655c5dcbb9"
      },
      "source": [
        "print(\"Dimensions for Train data are {0} x {1}\".format(x_train.shape[1],x_train.shape[2]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensions for Train data are 28 x 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jtdZ7RqJjv8",
        "colab_type": "text"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAD3q5I6Jjv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5BRBzBJjwD",
        "colab_type": "text"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fUQpMHxJjwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32') \n",
        "x_train = x_train// 255\n",
        "x_test = x_test.astype('float32')\n",
        "x_test = x_test// 255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5-DwgrJjwM",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5shnDmJ-ZsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding depth parameter\n",
        "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRRTJq8JjwQ",
        "colab_type": "text"
      },
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WmbgoJW-9xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWTZYnKSJjwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "876573d5-d065-4684-cb7a-1ab55aa8656d"
      },
      "source": [
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2,  activation='relu', input_shape=(28,28,1)))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.25))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0818 14:11:39.551144 140095462152064 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18AoS7eJjwU",
        "colab_type": "text"
      },
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DORCLgSwJjwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRW_XVYBGLZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlyStopingPatience = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8agB9_EDUYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLwt43W1DUtJ",
        "colab_type": "code",
        "outputId": "f0512f5d-6071-497f-adbd-67467a2cc3da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32, callbacks=[earlyStopingPatience])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 11s 191us/sample - loss: 1.5589 - acc: 0.4294 - val_loss: 1.4821 - val_acc: 0.4482\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4532 - acc: 0.4618 - val_loss: 1.4521 - val_acc: 0.4640\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4148 - acc: 0.4765 - val_loss: 1.4484 - val_acc: 0.4665\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 1.3823 - acc: 0.4889 - val_loss: 1.4492 - val_acc: 0.4643\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 1.3498 - acc: 0.4986 - val_loss: 1.4595 - val_acc: 0.4627\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 126us/sample - loss: 1.3181 - acc: 0.5128 - val_loss: 1.4716 - val_acc: 0.4599\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 125us/sample - loss: 1.2874 - acc: 0.5238 - val_loss: 1.4838 - val_acc: 0.4602\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 125us/sample - loss: 1.2602 - acc: 0.5354 - val_loss: 1.5171 - val_acc: 0.4624\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6a38c77e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju69vKdIJjwX",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK-Soxq6L6zI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2hAP94vJjwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu')) # 128 neurons relu\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax')) # 10 neurons softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSL3GmoZI4MV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z78AuEHMQvH",
        "colab_type": "code",
        "outputId": "72c39cc0-1cda-41c9-faf1-2c5ad0440251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 1.5229 - acc: 0.4430 - val_loss: 1.4553 - val_acc: 0.4647\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 1.4237 - acc: 0.4742 - val_loss: 1.4344 - val_acc: 0.4713\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 1.3827 - acc: 0.4873 - val_loss: 1.4301 - val_acc: 0.4726\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 1.3456 - acc: 0.5016 - val_loss: 1.4433 - val_acc: 0.4679\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 1.3140 - acc: 0.5134 - val_loss: 1.4465 - val_acc: 0.4687\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 1.2813 - acc: 0.5276 - val_loss: 1.4741 - val_acc: 0.4695\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 1.2577 - acc: 0.5357 - val_loss: 1.4977 - val_acc: 0.4657\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 1.2373 - acc: 0.5430 - val_loss: 1.4822 - val_acc: 0.4685\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 1.2170 - acc: 0.5498 - val_loss: 1.5258 - val_acc: 0.4669\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 1.2014 - acc: 0.5562 - val_loss: 1.5431 - val_acc: 0.4691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6a2a30bda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGTA3bfEJjwa",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6gX8n5SJjwb",
        "colab_type": "text"
      },
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX8s8eFWDf3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = keras.preprocessing.image.ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
        "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbz4uHBuJjwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generatorTrain = datagen.flow(x_train,y_train, batch_size=64)\n",
        "generatorTest = datagen.flow(x_test,y_test, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-8dOo7Jjwf",
        "colab_type": "text"
      },
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DpI1_McYJjwg",
        "colab_type": "code",
        "outputId": "826338b3-25f1-45bb-ff60-73e7ba63e6c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze())\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAABcCAYAAABz9T77AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABF5JREFUeJzt3U2IVXUcx+HvjKPp2As5VtKLjUWS\nLSqsIFtIUjKrCowiCYIWvdgqohYRRUU7N0XYC7lwEREF0SaIalfkUIEwUWbqpBJISW+ClDXX2+I4\nA4NhXpW585t5ns29h3vPnT+Hmc/8zuXcmZ52ux0A6urt9gIAODVCDlCckAMUJ+QAxQk5QHFCDlCc\nkAMUJ+QAxQk5QHF9U/nF1vbeNSs+RvrxkXd7TvS5jsmxHJP/5rgcyzFpmMgBihNygOKEHKA4IQco\nTsgBihNygOKEHKA4IQcoTsgBihNygOKEHKA4IQcoTsgBihNygOKEHKA4IQcoTsgBihNygOKEHKA4\nIQcoTsgBihNygOKEHKA4IQcorq/bCwBOr76LLkyStM4/N0nS3vZNN5fDFDCRAxTXlYl898ZVSZK5\nh3qSJEuf/bzj15gzsGjSduuXXydt9102mCQZG93T+QKhsB2PXpokaS3+O0my/P5uroapYCIHKK4r\nE/nyzQeSJEdG9yVJ2h3s+/3rNyRJfrjtjSTJ9c9sSJIMbN6aJPnlgWbaP3jLoSTJsntOeblQyuVP\nbO14n96FC5MkB9ZfnSQZW9CcLV/wcudny9PBnheaDiz8sdk+77XOj0klJnKA4roykbd27DrpfVe8\n+HuSZOiha5MkA5n8m3Zg83Bz+0Ync/70M+eq5UmSP5eekySZ9+GX3VwOM9zYyub77avnX02SXPPF\n+uaBl5ub1s0rkyQvbdmUJHlscNXULrBDi0ean//+/YdPeJ+eviaH+96+Mkny7U1vJkmG1t3XPGF4\nJEky+lbTnv4v+pMkS17s/lmLiRyguHLXkbe27zz+E9q1J/Fx+9csTpJse+qVJMmab+5Iksxbu7dr\na2Lm6v10W5Jk6MJm2lyS7ZMe7/usmUYfv338EpjvpmxtJ+PMd4Y73qc9NpYkaW0/K0my6r2HkyRn\nD09+rUu2NNlcMLI7STJ20qs8fUzkAMWVm8hni/M3Ne+7DW06+n7cYHOmMf7bf86KKyae+79nKcX9\nce+NSZLhja8lSdbtWpskObT6QNfWNNuMT6vtkek9iZ8Og08f/wqXuR99lWR6TOLjTOQAxZnIixjb\ns2/S9uhz8yfuH9ndXEGw7MmZea3sok9GkySrH3kwSTL3YCtJ0pdmIv/n1uuSJD9t+Gtin4vv9PdF\nmD1M5ADFmciLuvTuryfu95xxRpLOPiFbSeunn5MkC97/+T8fn7/3tyRJ/wcXTNmaYDoxkQMUZyKf\nAdqHT/zTazNRa2fzHvqio7cw25jIAYoTcoDihBygOCEHKE7IAYoTcoDihBygOCEHKE7IAYoTcoDi\nhBygOCEHKE7IAYoTcoDihBygOCEHKK6n3Z6p/yAMYHYwkQMUJ+QAxQk5QHFCDlCckAMUJ+QAxQk5\nQHFCDlCckAMUJ+QAxQk5QHFCDlCckAMUJ+QAxQk5QHFCDlCckAMUJ+QAxQk5QHFCDlCckAMUJ+QA\nxQk5QHH/AkHrweI3T2JKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmPl5yE8Jjwm",
        "colab_type": "text"
      },
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ZnDdJYJjwn",
        "colab_type": "code",
        "outputId": "daeef7f5-3ddc-44d3-8cb7-aef9bcc17b3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.fit_generator(generatorTrain, epochs=10, validation_data=generatorTest)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 2.0888 - acc: 0.2270 - val_loss: 2.0199 - val_acc: 0.2565\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 2.0025 - acc: 0.2598 - val_loss: 1.9878 - val_acc: 0.2680\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 1.9742 - acc: 0.2675 - val_loss: 1.9573 - val_acc: 0.2744\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 18s 20ms/step - loss: 1.9590 - acc: 0.2740 - val_loss: 1.9486 - val_acc: 0.2792\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 1.9473 - acc: 0.2775 - val_loss: 1.9434 - val_acc: 0.2702\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 1.9353 - acc: 0.2805 - val_loss: 1.9339 - val_acc: 0.2818\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 1.9321 - acc: 0.2814 - val_loss: 1.9209 - val_acc: 0.2887\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 1.9250 - acc: 0.2859 - val_loss: 1.9262 - val_acc: 0.2890\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 1.9159 - acc: 0.2892 - val_loss: 1.9186 - val_acc: 0.2849\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 18s 20ms/step - loss: 1.9170 - acc: 0.2903 - val_loss: 1.9226 - val_acc: 0.2867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6a2046c1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeI1mgaGW80w",
        "colab_type": "code",
        "outputId": "5477613e-1390-45f3-9381-defd9d0a7210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6DO7BQGW7mo",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQQW5iOJjwq",
        "colab_type": "text"
      },
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1SrtBEPJjwq",
        "colab_type": "code",
        "outputId": "f97cde1b-9c44-4068-e038-f8afd41d6d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result=model.evaluate(x_test,y_test,verbose=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 79us/sample - loss: 1.7365 - acc: 0.3512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBwVWNQC2qZD",
        "colab_type": "code",
        "outputId": "7c6711e7-762d-4b8e-d246-b63b44fb8fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Model Accuracy is : \",result[1]*100)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy is :  35.120001435279846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT9WojpoZbfN",
        "colab_type": "code",
        "outputId": "89bd6c15-d7d3-46e0-9aaa-1777027e5bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Model Loss is : \",result[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Loss is :  1.736462162399292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KXqmUDW2rM1",
        "colab_type": "text"
      },
      "source": [
        "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mja6OgQ3L18",
        "colab_type": "text"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HzVTPUM3WZJ",
        "colab_type": "text"
      },
      "source": [
        "### **Import necessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPM558TX4KMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvUaZuE-deDu",
        "colab_type": "text"
      },
      "source": [
        "### **Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QecXAzc4UGTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8cb04fa1-2c80-4b8f-817a-5696a889e66a"
      },
      "source": [
        "(cifar_x_train, cifar_y_train), (cifar_x_test, cifar_y_test) = cifar10.load_data()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60ws2TlFZvK_",
        "colab_type": "code",
        "outputId": "be2ac27c-7abb-4819-85fd-e3782724cfbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(cifar_x_train.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Z0w8G2Z4tV",
        "colab_type": "code",
        "outputId": "303e9949-5ebf-4423-ce01-583309db8a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(cifar_y_train.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvqxTE28ZzFs",
        "colab_type": "code",
        "outputId": "f0999e64-9c93-4ea4-8d14-1529f9ee67ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(cifar_x_test.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3vYYhK4W0u",
        "colab_type": "text"
      },
      "source": [
        "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbekTKi4cmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = keras.preprocessing.image.ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
        "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
        "\thorizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-SLtUhC4dK2",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCAPC2AMcsqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen.fit(cifar_x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kln2ko8zc20s",
        "colab_type": "code",
        "outputId": "244cc396-64df-485c-ef0a-53668c25485b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cifar_x_train.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYyF-P8O4jQ8",
        "colab_type": "text"
      },
      "source": [
        "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXug4z234mwQ",
        "colab_type": "code",
        "outputId": "c821cd2e-9f67-463d-f481-71ad46d363f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(cifar_x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().astype(np.uint8).squeeze())\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABcCAYAAAB3AO7GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxcoVFbuAW7FixcoVFbuAW7FixcoVlf8fGIXOJg+TtsQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A9j6lwmGDxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}